{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from xgboost import plot_importance, XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from time import time\n",
    "import umap\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "Y = np.load('Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((X, X, X), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2062, 64, 64, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle de convolution avec Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 64, 64, 3)\n",
      "(619, 64, 64, 3)\n",
      "(1443, 10)\n",
      "(619, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((1443, 64, 64, -1))\n",
    "X_valid = X_valid.reshape((619, 64, 64, -1))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "vgg_base = VGG16(weights=\"imagenet\", include_top=False, classes=10, input_shape=(64,64,3))\n",
    "print(vgg_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "model = Sequential()\n",
    "model.add(vgg_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8192, activation='elu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(4096, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "#checkpoint = keras.callbacks.ModelCheckpoint(\"Weights/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1443 samples, validate on 619 samples\n",
      "Epoch 1/15\n",
      "1443/1443 [==============================] - 176s 122ms/step - loss: 14.5431 - accuracy: 0.0977 - val_loss: 0.0566 - val_accuracy: 0.1050\n",
      "Epoch 2/15\n",
      "1443/1443 [==============================] - 179s 124ms/step - loss: 14.5096 - accuracy: 0.0998 - val_loss: 0.0566 - val_accuracy: 0.1050\n",
      "Epoch 3/15\n",
      "1443/1443 [==============================] - 179s 124ms/step - loss: 14.4650 - accuracy: 0.1026 - val_loss: 0.0566 - val_accuracy: 0.1050\n",
      "Epoch 4/15\n",
      "1443/1443 [==============================] - 180s 124ms/step - loss: 14.5096 - accuracy: 0.0998 - val_loss: 0.0566 - val_accuracy: 0.1050\n",
      "Epoch 5/15\n",
      "1443/1443 [==============================] - 180s 125ms/step - loss: 14.5990 - accuracy: 0.0942 - val_loss: 0.0566 - val_accuracy: 0.1050\n",
      "Epoch 6/15\n",
      "1443/1443 [==============================] - 194s 135ms/step - loss: 14.3868 - accuracy: 0.1074 - val_loss: 0.0566 - val_accuracy: 0.1050\n",
      "Epoch 7/15\n",
      "1443/1443 [==============================] - 226s 157ms/step - loss: 14.5431 - accuracy: 0.0977 - val_loss: 0.0576 - val_accuracy: 0.0889\n",
      "Epoch 8/15\n",
      "1443/1443 [==============================] - 227s 157ms/step - loss: 14.4091 - accuracy: 0.1060 - val_loss: 0.0576 - val_accuracy: 0.0889\n",
      "Epoch 9/15\n",
      "1443/1443 [==============================] - 179s 124ms/step - loss: 14.4091 - accuracy: 0.1060 - val_loss: 0.0576 - val_accuracy: 0.0889\n",
      "Epoch 10/15\n",
      "1443/1443 [==============================] - 180s 125ms/step - loss: 14.4091 - accuracy: 0.1060 - val_loss: 0.0576 - val_accuracy: 0.0889\n",
      "Epoch 11/15\n",
      "1443/1443 [==============================] - 177s 123ms/step - loss: 14.4091 - accuracy: 0.1060 - val_loss: 0.0576 - val_accuracy: 0.0889\n",
      "Epoch 12/15\n",
      " 448/1443 [========>.....................] - ETA: 1:51 - loss: 14.8229 - accuracy: 0.0804"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-11650bf3c0e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train/255.0, y_train, batch_size=32, epochs=15, verbose=1, validation_data=(X_valid/255.0,y_valid/255.0), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='vgg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = X[2]\n",
    "image = np.pad(image, pad_width=80, mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.dstack((image, image, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-448b1047b853>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# convert the probabilities to class labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# retrieve the most likely result, e.g. highest probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\keras_applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m                          \u001b[1;34m'a batch of predictions '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                          \u001b[1;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                          'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[0;32m    223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         fpath = keras_utils.get_file(\n",
      "\u001b[1;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 10)"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image = load_img('../images/mug.jpg', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_valid_flat, Y_predict)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ok = []\n",
    "true = 0\n",
    "false = 0\n",
    "for i in range(len(Y_predict)):\n",
    "    if Y_predict[i] == y_valid_flat[i]:\n",
    "        p = True \n",
    "        true += 1    \n",
    "    else:\n",
    "        p = False\n",
    "        false += 1\n",
    "    predict_ok.append(p)\n",
    "                \n",
    "predict_ok\n",
    "print('Nombres de prédictions Valide :',true)\n",
    "print('Nombres de mauvaise prédictions :',false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(conf_mat, range(10),\n",
    "                  range(10))\n",
    "df.rename_axis('Prédites').rename_axis('Réelles', axis='columns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
